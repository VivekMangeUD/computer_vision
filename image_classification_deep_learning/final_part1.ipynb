{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NLW8swLjiE5E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIX1s_7F0oFi",
        "outputId": "d3320c65-d527-4daf-85fb-a82070d0a254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "m4gBbr1YX_JF"
      },
      "outputs": [],
      "source": [
        "data_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DacKyl5wTtXW",
        "outputId": "25b8f8b2-d686-4592-9739-8884a621f514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = datasets.CIFAR100(root='./data', train = True, transform = data_transforms, download=True)\n",
        "\n",
        "testset = datasets.CIFAR100(root='./data', train=False, transform = data_transforms,\n",
        "download=True)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=256,shuffle=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3-xewvpKByvx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VCEGB8URZ4y_"
      },
      "outputs": [],
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "num_in_ftrs = model.classifier[6].in_features\n",
        "num_cls = len(trainset.classes)\n",
        "model.classifier[6] = nn.Linear(num_in_ftrs, num_cls)\n",
        "\n",
        "for param in model.parameters(): # freeze all the layers\n",
        "  param.requires_grad = False\n",
        "\n",
        "for param in model.classifier[6].parameters(): # unfreeze the last linear layer.\n",
        "  param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vXEMrx2Bd1o6"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30\n",
        "# num_epochs = 15\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9HBWPgzf9Aj",
        "outputId": "296bcbc7-fb71-4ced-8c63-c18e39809fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter 1 for training : 0\n"
          ]
        }
      ],
      "source": [
        "train = int(input(\"Enter 1 for training : \"))\n",
        "if train == 1:\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      loss = 0.0\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          images, labels = data\n",
        "          # images, labels = images.cuda(), labels.cuda() # For GPU use\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          loss += loss.item()\n",
        "          if i % 2000 == 1999:    # print every mini-batches\n",
        "              print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, loss / 2000))\n",
        "              loss = 0.0\n",
        "\n",
        "  print('Finished Training')\n",
        "  torch.save(model.state_dict(), 'best_model.pth')\n",
        "  # torch.save(best_model_wts , '/content/drive/MyDrive/computer_vision/PR2/part1/best_model_weight_PR2_13.pth')\n",
        "else:\n",
        "  # model.load_state_dict(torch.load('best_model.pth'))\n",
        "  model.load_state_dict(torch.load('/content/drive/MyDrive/computer_vision/PR2/part1/best_model_weight_PR2_2.pth', map_location=torch.device('cpu')))\n",
        "  model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2m5A9IJ2p8Z"
      },
      "outputs": [],
      "source": [
        "true_pos = 0\n",
        "total_detect = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        total_detect += labels.size(0)\n",
        "        true_pos += (preds == labels).sum().item()\n",
        "\n",
        "print('Accuracy : %d %%' % (\n",
        "    100 * true_pos / total_detect))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGZkMas9M31v"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9oMz9fbzB1cC"
      },
      "source": [
        "Batch size - 16 -  \n",
        "epoch  = 10\n",
        "accuracy - 54\n",
        "\n",
        "---\n",
        "\n",
        "Batch size - 64 -  \n",
        "epoch  = 10\n",
        "accuracy - 61\n",
        "\n",
        "---\n",
        "\n",
        "Batch size - 64 -  \n",
        "learning_rate = 0.0001\n",
        "epoch  = 10\n",
        "accuracy - 49\n",
        "\n",
        "---\n",
        "\n",
        "Batch size - 128 -  \n",
        "learning_rate = 0.001\n",
        "epoch  = 15\n",
        "accuracy - 56\n",
        "\n",
        "---\n",
        "Batch size - 256 -  \n",
        "learning_rate = 0.0001\n",
        "epoch  = 50\n",
        "accuracy - 52 - Failed - Ask to use pro for long time\n",
        "Started at 3.09 am - check the file creation time to see the trainning ending\n",
        "\n",
        "---\n",
        "Batch size - 256 -  \n",
        "learning_rate = 0.0001\n",
        "epoch  = 30\n",
        "accuracy - 55\n",
        "Started at 10.44 am - check the file creation time to see the trainning ending\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ImVtjlMGPEOb"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
