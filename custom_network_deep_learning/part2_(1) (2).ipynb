{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojsM-4vm6y-l"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6V9SegA67jT"
      },
      "source": [
        "data_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXF_QQ-96_9e",
        "outputId": "595ab36e-ec0f-418e-b4b4-19c10fb10366"
      },
      "source": [
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train = True, transform = data_transforms, download=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, transform = data_transforms,\n",
        "download=True)\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:12<00:00, 13350670.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj__Xern7ERe"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3,1,1, padding_mode='replicate')\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3,1,1, padding_mode='replicate')\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3,1,1, padding_mode='replicate')\n",
        "        self.fc1 = nn.Linear(28*28*64, 5000)\n",
        "        self.fc2 = nn.Linear(5000, 100)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 28*28*64)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFetB0PK7Eqr"
      },
      "source": [
        "num_epochs = 30\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUqSnsqE7HWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb30dda8-0871-4cd1-d496-e5c5ff39c8c2"
      },
      "source": [
        "\n",
        "train = int(input(\"Enter 1 to train:\"))\n",
        "if train == 1:\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          if i % 2000 == 1999:    # print mini-batches\n",
        "              print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 2000))\n",
        "              running_loss = 0.0\n",
        "\n",
        "\n",
        "  torch.save(model.state_dict(), 'best_model.pth')\n",
        "  print('Finished Training')\n",
        "else:\n",
        "  model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1 to train otherwise 0:1\n",
            "[1,  2000] loss: 3.498\n",
            "[2,  2000] loss: 2.521\n",
            "[3,  2000] loss: 2.032\n",
            "[4,  2000] loss: 1.529\n",
            "[5,  2000] loss: 1.024\n",
            "[6,  2000] loss: 0.653\n",
            "[7,  2000] loss: 0.429\n",
            "[8,  2000] loss: 0.296\n",
            "[9,  2000] loss: 0.223\n",
            "[10,  2000] loss: 0.180\n",
            "[11,  2000] loss: 0.150\n",
            "[12,  2000] loss: 0.121\n",
            "[13,  2000] loss: 0.099\n",
            "[14,  2000] loss: 0.092\n",
            "[15,  2000] loss: 0.087\n",
            "[16,  2000] loss: 0.072\n",
            "[17,  2000] loss: 0.066\n",
            "[18,  2000] loss: 0.062\n",
            "[19,  2000] loss: 0.063\n",
            "[20,  2000] loss: 0.059\n",
            "[21,  2000] loss: 0.061\n",
            "[22,  2000] loss: 0.051\n",
            "[23,  2000] loss: 0.051\n",
            "[24,  2000] loss: 0.042\n",
            "[25,  2000] loss: 0.044\n",
            "[26,  2000] loss: 0.045\n",
            "[27,  2000] loss: 0.041\n",
            "[28,  2000] loss: 0.040\n",
            "[29,  2000] loss: 0.034\n",
            "[30,  2000] loss: 0.036\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q611LAw37RZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ccc0b87-d840-4557-8efe-f83755f4338a"
      },
      "source": [
        "true_pos = 0\n",
        "total_detect = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_detect += labels.size(0)\n",
        "        true_pos += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy : %d %%' % (\n",
        "    100 * true_pos / total_detect))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 37 %\n"
          ]
        }
      ]
    }
  ]
}